{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "229200f3-0f8b-46fb-906f-47845bcd6951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p cnf 15 41\n",
      "1 2 3 0\n",
      "4 5 6 0\n",
      "7 8 9 0\n",
      "10 11 12 0\n",
      "13 14 15 0\n",
      "-1 -2 0\n",
      "-1 -3 0\n",
      "-2 -3 0\n",
      "-4 -5 0\n",
      "-4 -6 0\n",
      "-5 -6 0\n",
      "-7 -8 0\n",
      "-7 -9 0\n",
      "-8 -9 0\n",
      "-10 -11 0\n",
      "-10 -12 0\n",
      "-11 -12 0\n",
      "-13 -14 0\n",
      "-13 -15 0\n",
      "-14 -15 0\n",
      "-1 -4 0\n",
      "-2 -5 0\n",
      "-3 -6 0\n",
      "-1 -10 0\n",
      "-2 -11 0\n",
      "-3 -12 0\n",
      "-4 -7 0\n",
      "-5 -8 0\n",
      "-6 -9 0\n",
      "-4 -10 0\n",
      "-5 -11 0\n",
      "-6 -12 0\n",
      "-4 -13 0\n",
      "-5 -14 0\n",
      "-6 -15 0\n",
      "-7 -10 0\n",
      "-8 -11 0\n",
      "-9 -12 0\n",
      "-7 -13 0\n",
      "-8 -14 0\n",
      "-9 -15 0\n"
     ]
    }
   ],
   "source": [
    "!cat './data/id=10_n=5_p=0.5_k=3.cnf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7bcff9c-5cc3-47d9-9361-cfa3b88e75dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdb\n",
    "import random\n",
    "from collections import namedtuple\n",
    "\n",
    "import scipy.sparse as sparse\n",
    "import torch\n",
    "\n",
    "from cnf import CNF\n",
    "from util import DataSample, adj, adj_batch, init_edge_attr, to_sparse_tensor\n",
    "\n",
    "\n",
    "Batch = namedtuple('Batch', ['x', 'adj', 'sol'])\n",
    "SampleWrapper = namedtuple('SampleWrapper', ['ptype', 'sample'])\n",
    "\n",
    "\n",
    "def load_dir(path):\n",
    "    data = []\n",
    "    for filename in os.listdir(path):\n",
    "        name, ext = os.path.splitext(filename)\n",
    "        if ext != '.cnf':\n",
    "            continue\n",
    "        f = CNF.from_file(os.path.join(path, filename))\n",
    "        if name.startswith('uu'):\n",
    "            continue\n",
    "        data.append(DataSample(filename, f, adj(f), None))\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_dir_wrapper(path):\n",
    "    data = load_dir(path)\n",
    "    return [SampleWrapper(ptype, sample) for sample in data]\n",
    "\n",
    "\n",
    "def init_tensor_wrapper(sample_wrapper, device):\n",
    "    return (sample_wrapper.ptype, init_tensors(sample_wrapper.sample, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce36310d-36e4-453d-9e05-382232651612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a2e758e-ed12-4dbc-a41b-49739e5d1b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dir('../data/kcolor/3-5-0.5/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9514d11-a2ce-4c9d-b07f-4ebd10d7f557",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def adj_sign(n, m, occur):\n",
    "    i = np.repeat(range(n), [len(lst) for lst in occur])\n",
    "    j = np.concatenate(occur)\n",
    "    v = np.ones(len(i), dtype=np.int64)\n",
    "    return sparse.coo_matrix((v, (i, j)), shape=(n, m))\n",
    "\n",
    "\n",
    "def adj(f):\n",
    "    n, m, occur = f.n_variables, len(f.clauses), f.occur_list\n",
    "    adj_pos = adj_sign(n, m, occur[1 : n + 1])\n",
    "    adj_neg = adj_sign(n, m, occur[:n:-1])\n",
    "    return (adj_pos, adj_neg)\n",
    "\n",
    "\n",
    "def adj_batch(adjs, fstack):\n",
    "    adjp, adjn = list(zip(*adjs))\n",
    "    return fstack((sparse.block_diag(adjp), sparse.block_diag(adjn)))\n",
    "\n",
    "\n",
    "def to_sparse_tensor(x):\n",
    "    x = x.tocoo()\n",
    "    i = torch.tensor(np.vstack((x.row, x.col)), dtype=torch.int64)\n",
    "    v = torch.tensor(x.data, dtype=torch.float32)\n",
    "    return torch.sparse_coo_tensor(i, v, torch.Size(x.shape))\n",
    "\n",
    "def init_edge_attr(k):\n",
    "    return torch.cat(\n",
    "        (\n",
    "            torch.tensor([1, 0], dtype=torch.float32).expand(k, 2),\n",
    "            torch.tensor([0, 1], dtype=torch.float32).expand(k, 2),\n",
    "        ),\n",
    "        dim=0,\n",
    "    )\n",
    "\n",
    "\n",
    "def normalize(x):\n",
    "    return 2 * x - 1\n",
    "\n",
    "\n",
    "def unnormalize(x):\n",
    "    return (x + 1) / 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee555431-9bad-4c33-ba85-9a46bce6c0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_tensors(sample, device):\n",
    "    # [1,0,0] -> assigned False\n",
    "    # [0,1,0] -> assigned True\n",
    "    # [0,0,1] -> clause\n",
    "    adj = sample.adj\n",
    "    n, m = adj[0].shape[0], adj[0].shape[1]\n",
    "    xv = torch.zeros(n, 3, dtype=torch.float32)\n",
    "    sol = [x if random.random() < 0.5 else -x for x in range(n + 1)]\n",
    "    xv[torch.arange(n), (torch.tensor(sol[1:]) > 0).long()] = 1\n",
    "    xv = xv.to(device)\n",
    "    xc = torch.tensor([0, 0, 1], dtype=torch.float32).repeat(m, 1).to(device)\n",
    "    xev = init_edge_attr(n).to(device)\n",
    "    xec = init_edge_attr(m).to(device)\n",
    "    vadj = to_sparse_tensor(sparse.hstack(adj)).to(device)\n",
    "    cadj = to_sparse_tensor(sparse.vstack(adj)).t().to(device)\n",
    "    return Batch((xv, xc, xev, xec), (vadj, cadj), sol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9843017-3974-49b3-a19f-ed27fcf42865",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b63b47a4-cbe3-4cf8-ad3a-96d854a82b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = init_tensors(data[53], device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ba0d4ea-40df-461c-b442-30b6124fd870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  3,  3,\n",
       "        3,  3,  3,  4,  4,  4,  4,  4,  5,  5,  5,  5,  5,  6,  6,  6,  6,\n",
       "        6,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  9,  9,  9,  9, 10, 10,\n",
       "       10, 10, 11, 11, 11, 11, 12, 12, 12, 13, 13, 13, 14, 14, 14])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = data[3].formula\n",
    "n,m,occur=f.n_variables, len(f.clauses), f.occur_list\n",
    "np.repeat(range(n), [len(lst) for lst in occur[:n:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d95a846-be70-45d2-a9fd-bfb7c9360c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.repeat(range(n), [len(lst) for lst in occur[1:n+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da473d1a-956f-4d59-8433-61a013238954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef adj_sign(n, m, occur):\\n    i = np.repeat(range(n), [len(lst) for lst in occur])\\n    j = np.concatenate(occur)\\n    v = np.ones(len(i), dtype=np.int64)\\n    return sparse.coo_matrix((v, (i, j)), shape=(n, m))\\n\\n\\ndef adj(f):\\n    n, m, occur = f.n_variables, len(f.clauses), f.occur_list\\n    adj_pos = adj_sign(n, m, occur[1 : n + 1])\\n    adj_neg = adj_sign(n, m, occur[:n:-1])\\n    return (adj_pos, adj_neg)\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def adj_sign(n, m, occur):\n",
    "    i = np.repeat(range(n), [len(lst) for lst in occur])\n",
    "    j = np.concatenate(occur)\n",
    "    v = np.ones(len(i), dtype=np.int64)\n",
    "    return sparse.coo_matrix((v, (i, j)), shape=(n, m))\n",
    "\n",
    "\n",
    "def adj(f):\n",
    "    n, m, occur = f.n_variables, len(f.clauses), f.occur_list\n",
    "    adj_pos = adj_sign(n, m, occur[1 : n + 1])\n",
    "    adj_neg = adj_sign(n, m, occur[:n:-1])\n",
    "    return (adj_pos, adj_neg)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26ccddc7-277b-4ab5-87c2-b849c68968b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_sparse_tensor_experiment(sparse.coo_array(data[49].adj[0].todense()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c050f25e-393c-42b4-9cd3-dfb8e1f9f294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[3].adj[0].todense()[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5bcd87e-726e-4266-bfe3-77cc467a8b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([870])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.adj[0].to_dense().view(-1,).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b06f80b7-7bd4-4636-9c20-ff2998883d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.x[2].shape  #edge 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7df25025-d329-4b66-af01-56b6c97dcc88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 58])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.adj[0].to_dense().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa33ffcb-0bb1-4d0d-8b13-e6ebf5af85d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(tensor[0][0], tensor[0][1].transpose(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f609d8f-afbf-493c-847c-8b97b31ee0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vgae import VGAE, GraphEncoder, VGAEEncoder\n",
    "from train_search import vgae_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38ed9bb1-596a-496b-8297-202c2bfb4740",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = VGAE(3,32,16,mlp_arch={'hidden_sizes': [32], 'activation': \"ReLU\"}, gnn_iter=3, gnn_async=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b1fdbe7-b41e-4b98-97bc-9f3540787db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weak_encoder = VGAEEncoder(3,32,16,mlp_arch={'hidden_sizes': [32], 'activation': \"ReLU\"}, gnn_iter=3, gnn_async=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b4a96c8-db7b-47d6-bda3-0f3dd92ba426",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_rec, mean, log_var = encoder(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c1d01e8-fa43-4812-8961-1e314dfe55e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(426.3470, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgae_loss(adj_rec, tensor.adj[0], mean, log_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "448a488c-7f95-49ee-9838-b23f672e49d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjref = tensor.adj[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00118cd3-9383-4b3b-b4d2-5655a6d12db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, m = adjref.shape\n",
    "adjref1, adjref2 = torch.split(adjref.to_dense(), m//2, dim=1)\n",
    "adj = adjref1 - adjref2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "18ada846-603b-40bd-91f5-81d1f36a25e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8.4397e-02, 2.5994e-08, 9.4079e-01, 6.3401e-01, 5.5460e-02, 1.2074e-01,\n",
       "         8.1879e-01, 7.0147e-11, 7.2899e-01, 1.0000e+00, 1.0000e+00, 6.0453e-02,\n",
       "         9.9992e-01, 8.9899e-01, 9.9838e-01, 7.4729e-12, 9.9999e-01, 4.3594e-04,\n",
       "         1.0000e+00, 9.9642e-01, 4.3379e-11, 4.4682e-06, 2.6908e-08, 9.9228e-01,\n",
       "         1.0918e-02, 1.5033e-04, 9.9979e-01, 5.0643e-12, 9.5589e-01],\n",
       "        [1.0904e-05, 4.0763e-09, 8.9375e-01, 1.1441e-02, 1.6655e-04, 2.7593e-06,\n",
       "         2.2924e-07, 2.0042e-04, 2.0920e-01, 9.9992e-01, 1.0000e+00, 1.2708e-05,\n",
       "         9.9427e-01, 1.0000e+00, 5.3287e-01, 5.7408e-03, 2.4491e-01, 8.5548e-01,\n",
       "         1.0000e+00, 9.9920e-01, 2.5079e-04, 1.9758e-11, 1.4222e-01, 1.0000e+00,\n",
       "         5.6219e-06, 3.6897e-01, 1.7739e-01, 4.2417e-04, 5.4920e-02],\n",
       "        [5.7469e-06, 9.0720e-05, 2.5114e-07, 9.9977e-01, 1.0000e+00, 1.0410e-04,\n",
       "         4.0634e-11, 2.2994e-03, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.1331e-06,\n",
       "         9.7567e-01, 4.4257e-10, 9.7903e-01, 9.1491e-01, 9.2149e-01, 9.9868e-01,\n",
       "         1.0000e+00, 3.9033e-08, 1.0000e+00, 4.5182e-03, 3.8021e-06, 9.9984e-01,\n",
       "         9.9851e-01, 7.0475e-15, 9.6821e-01, 1.9024e-09, 3.9560e-01],\n",
       "        [1.5778e-05, 9.9968e-01, 8.3612e-01, 1.0000e+00, 2.2151e-07, 3.6036e-04,\n",
       "         8.3977e-01, 3.3076e-05, 9.9912e-01, 2.5042e-05, 9.9994e-01, 8.1873e-01,\n",
       "         2.2880e-01, 1.0000e+00, 9.9834e-01, 9.1669e-03, 3.2235e-06, 9.8399e-01,\n",
       "         1.8303e-03, 1.0000e+00, 9.9956e-01, 5.6492e-01, 1.0192e-02, 9.9997e-01,\n",
       "         1.6990e-01, 9.9987e-01, 9.9988e-01, 9.6082e-01, 8.5354e-01],\n",
       "        [9.9248e-01, 1.7779e-01, 1.3950e-01, 5.4483e-02, 4.3062e-05, 4.5868e-06,\n",
       "         3.0563e-01, 6.0091e-02, 9.9806e-01, 9.9662e-01, 4.2045e-01, 2.0229e-01,\n",
       "         1.6477e-01, 9.9994e-01, 9.8450e-01, 9.9947e-01, 6.5615e-01, 9.9811e-01,\n",
       "         9.9633e-01, 9.8575e-01, 9.9996e-01, 3.6384e-05, 9.9994e-01, 3.8372e-03,\n",
       "         8.9659e-01, 8.1957e-01, 6.2055e-01, 9.9735e-01, 9.6673e-02],\n",
       "        [3.6077e-06, 5.5657e-01, 9.9988e-01, 9.5923e-01, 9.8781e-01, 2.4955e-01,\n",
       "         7.7415e-06, 9.6982e-07, 8.8450e-01, 9.9947e-01, 1.0000e+00, 7.0116e-01,\n",
       "         7.1771e-01, 9.9804e-01, 9.5479e-01, 7.8670e-06, 1.0093e-01, 1.8267e-02,\n",
       "         9.9991e-01, 9.9999e-01, 2.7332e-06, 3.0175e-01, 1.9952e-03, 9.5810e-01,\n",
       "         7.9135e-01, 2.3832e-03, 9.9275e-01, 2.3378e-03, 9.5076e-01],\n",
       "        [1.0000e+00, 9.9602e-01, 6.3910e-03, 4.0414e-03, 7.3272e-01, 1.0000e+00,\n",
       "         1.0000e+00, 1.0000e+00, 2.5313e-07, 4.7189e-10, 4.9496e-07, 9.9973e-01,\n",
       "         5.1150e-03, 2.8075e-01, 2.9208e-07, 7.3139e-05, 5.6209e-04, 4.1237e-02,\n",
       "         7.8686e-12, 1.7159e-06, 9.9944e-01, 9.5090e-01, 1.5169e-01, 4.7749e-04,\n",
       "         6.4884e-03, 9.6482e-01, 9.9667e-03, 9.9858e-01, 1.0741e-03],\n",
       "        [1.0000e+00, 9.8538e-01, 3.7910e-02, 1.0500e-04, 9.6585e-01, 1.1126e-04,\n",
       "         1.0000e+00, 5.4113e-03, 9.9201e-01, 4.6034e-01, 3.7348e-01, 3.2125e-01,\n",
       "         1.4264e-03, 1.1837e-01, 9.9433e-01, 1.3366e-04, 9.9990e-01, 9.9993e-01,\n",
       "         1.6798e-03, 9.1255e-01, 1.0000e+00, 9.4582e-01, 1.0000e+00, 1.1738e-12,\n",
       "         7.4266e-01, 9.6800e-01, 3.7515e-01, 9.9982e-01, 9.8189e-04],\n",
       "        [9.9993e-01, 1.0000e+00, 1.5737e-01, 9.1870e-01, 9.6304e-01, 6.9420e-03,\n",
       "         4.5525e-03, 9.9954e-01, 5.5349e-01, 1.1491e-05, 8.4849e-01, 9.6456e-01,\n",
       "         4.7733e-03, 9.9908e-01, 1.0356e-02, 9.9995e-01, 4.3145e-05, 9.9824e-01,\n",
       "         9.4982e-07, 8.6332e-01, 9.9586e-01, 9.1013e-01, 9.8257e-01, 4.9999e-04,\n",
       "         1.7769e-01, 8.3480e-02, 9.3661e-03, 9.9999e-01, 3.0169e-01],\n",
       "        [9.9833e-01, 6.6437e-01, 9.9956e-01, 3.7822e-03, 5.0582e-01, 1.1086e-04,\n",
       "         9.7786e-01, 9.9999e-01, 1.4937e-02, 1.0000e+00, 1.1510e-02, 2.0263e-01,\n",
       "         9.9948e-01, 1.0000e+00, 8.8066e-02, 2.1006e-04, 7.5927e-04, 8.0970e-01,\n",
       "         6.6851e-02, 8.8622e-01, 1.0763e-02, 3.5267e-05, 9.9998e-01, 2.2944e-05,\n",
       "         3.2027e-01, 7.0294e-04, 9.8491e-01, 5.9608e-01, 3.9039e-02],\n",
       "        [1.1369e-07, 6.9274e-02, 9.6541e-07, 3.5319e-01, 1.0000e+00, 1.1231e-07,\n",
       "         1.0307e-02, 9.8009e-01, 8.1110e-01, 9.8100e-01, 9.9173e-01, 8.5403e-06,\n",
       "         9.9761e-01, 6.0627e-08, 9.9982e-01, 2.0075e-01, 9.8891e-01, 1.1891e-03,\n",
       "         9.7662e-01, 2.0538e-02, 4.8876e-03, 2.4360e-01, 9.9999e-01, 9.4711e-01,\n",
       "         1.0301e-03, 5.5229e-02, 5.2838e-08, 9.6427e-01, 7.0134e-06],\n",
       "        [9.9714e-01, 7.2760e-02, 3.2841e-02, 1.8271e-02, 5.3873e-01, 7.9167e-10,\n",
       "         1.7114e-03, 7.2665e-06, 5.3602e-01, 2.3531e-01, 4.6394e-02, 4.6696e-01,\n",
       "         8.7000e-01, 8.7063e-01, 9.3940e-01, 1.0000e+00, 9.9244e-01, 9.9607e-01,\n",
       "         9.9868e-01, 9.9893e-01, 4.1392e-05, 1.0016e-01, 8.2081e-01, 2.3125e-03,\n",
       "         9.0858e-02, 9.9999e-01, 7.1168e-04, 1.0000e+00, 5.2432e-04],\n",
       "        [9.9990e-01, 9.9309e-01, 1.0000e+00, 9.9979e-01, 5.4283e-04, 9.9997e-01,\n",
       "         1.2422e-02, 3.8324e-02, 6.9938e-04, 1.5293e-01, 9.2059e-01, 9.9995e-01,\n",
       "         2.3630e-01, 1.0000e+00, 7.4067e-01, 9.9973e-01, 7.5481e-04, 1.1780e-06,\n",
       "         6.8320e-02, 9.9940e-01, 1.3658e-06, 1.0000e+00, 7.1902e-01, 3.8990e-01,\n",
       "         1.4137e-03, 9.9794e-01, 9.9254e-01, 5.0407e-03, 9.9797e-01],\n",
       "        [1.0036e-08, 2.8353e-03, 9.9614e-01, 4.4870e-05, 2.3553e-05, 9.9992e-01,\n",
       "         2.5857e-09, 5.7720e-12, 9.9993e-01, 8.7786e-01, 1.3754e-02, 9.8999e-01,\n",
       "         2.9142e-05, 1.0820e-02, 6.8652e-01, 1.0000e+00, 9.9996e-01, 3.2917e-01,\n",
       "         9.9999e-01, 9.8428e-01, 9.9958e-01, 1.1120e-02, 6.4394e-01, 9.9594e-01,\n",
       "         9.9973e-01, 9.9991e-01, 9.9998e-01, 8.3632e-01, 1.0000e+00],\n",
       "        [9.2258e-01, 9.9585e-01, 5.2139e-03, 9.5423e-01, 2.7268e-04, 1.0000e+00,\n",
       "         1.0000e+00, 9.9999e-01, 1.0221e-02, 1.0564e-04, 1.1439e-04, 2.2547e-01,\n",
       "         1.2902e-02, 9.6407e-01, 8.7426e-01, 9.9990e-01, 1.8181e-01, 8.8555e-07,\n",
       "         2.2532e-04, 5.4555e-04, 1.0000e+00, 1.0000e+00, 7.0500e-01, 9.9995e-01,\n",
       "         3.8420e-04, 3.9028e-01, 7.7169e-01, 1.6110e-04, 7.5598e-01]],\n",
       "       grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99dcfdc8-de1b-4cb7-b3e3-9bc5256be907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(adjref1.numpy() + adjref2.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f724c984-7109-4b3a-b3ef-9986ba3ec587",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgae = torch.load('../results/vgae_mixed_all_v1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33af6a02-3f20-40b8-afda-d5cb237d514b",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjtest, _, _ = vgae(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff553733-a4b2-4a9e-8a4a-1ea9aa53c074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0.]], grad_fn=<RoundBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjtest.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c90a1043-f2d7-4afd-9bb8-c6239a14159a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5735e-04, 1.3173e-07, 6.9354e-07, 4.9724e-06, 6.2692e-06, 3.8925e-06,\n",
       "         2.2955e-06, 1.4122e-04, 1.4366e-05, 4.2173e-06, 3.8106e-07, 9.1548e-05,\n",
       "         3.4579e-05, 6.1913e-05, 6.7267e-05, 5.3562e-06, 1.1032e-05, 1.9796e-05,\n",
       "         1.8918e-05, 1.1570e-06, 2.7022e-08, 2.2878e-06, 8.9005e-08, 2.6242e-06,\n",
       "         1.3067e-06, 8.1779e-05, 9.8472e-07, 2.4191e-06, 8.6312e-07],\n",
       "        [1.6027e-04, 3.6427e-06, 2.2084e-08, 7.9706e-06, 2.3123e-08, 6.8429e-05,\n",
       "         5.8749e-06, 1.1878e-07, 3.2243e-06, 3.3107e-08, 1.0654e-08, 5.7488e-06,\n",
       "         5.2984e-07, 1.2576e-06, 2.2899e-07, 4.5911e-05, 4.9331e-08, 2.8434e-07,\n",
       "         1.7513e-07, 4.6050e-06, 1.0990e-06, 6.5403e-05, 1.5602e-07, 1.0984e-05,\n",
       "         1.0260e-05, 4.2227e-06, 2.7737e-05, 3.3318e-06, 7.3184e-05],\n",
       "        [2.9061e-06, 6.1817e-06, 5.2764e-06, 2.7553e-07, 6.9735e-07, 5.7716e-06,\n",
       "         2.9193e-06, 1.0713e-05, 1.8243e-05, 2.7116e-06, 1.9580e-07, 7.5119e-06,\n",
       "         3.3990e-07, 1.0685e-06, 2.2716e-06, 1.1974e-06, 1.4614e-07, 3.9742e-07,\n",
       "         2.1815e-06, 2.2419e-07, 3.8851e-06, 2.4071e-05, 8.7800e-08, 1.5487e-05,\n",
       "         6.3460e-06, 1.7985e-06, 3.4102e-06, 3.4529e-06, 3.0743e-07],\n",
       "        [2.8269e-07, 6.9953e-05, 7.5925e-05, 4.8163e-05, 2.6250e-07, 7.6163e-05,\n",
       "         1.5863e-04, 1.8625e-06, 6.0153e-05, 3.1163e-06, 1.5453e-05, 6.2798e-07,\n",
       "         2.0748e-07, 1.1996e-05, 6.0420e-08, 1.2338e-06, 6.5475e-08, 5.4841e-06,\n",
       "         2.0686e-07, 2.7553e-04, 5.5815e-04, 1.8851e-04, 4.0131e-06, 1.2316e-06,\n",
       "         8.5314e-06, 4.8790e-06, 4.6350e-08, 7.3992e-08, 8.8767e-05],\n",
       "        [2.8563e-07, 2.4880e-07, 2.2421e-06, 8.8168e-07, 4.8477e-07, 4.4541e-07,\n",
       "         1.9283e-06, 3.5220e-05, 2.4869e-05, 4.6201e-07, 7.5648e-07, 3.9120e-08,\n",
       "         1.8920e-06, 4.9779e-06, 7.7912e-07, 2.6288e-06, 6.7491e-08, 9.8360e-08,\n",
       "         1.5240e-07, 2.0157e-08, 1.7018e-07, 4.5975e-06, 4.5210e-07, 2.8354e-08,\n",
       "         1.8148e-07, 7.9744e-07, 1.6644e-08, 9.1746e-07, 8.9573e-07],\n",
       "        [1.9957e-05, 1.9061e-05, 3.7681e-06, 1.0516e-06, 1.5080e-05, 2.4210e-06,\n",
       "         3.4646e-05, 5.0535e-03, 2.9192e-04, 1.3977e-05, 2.1916e-05, 3.3362e-06,\n",
       "         5.1200e-07, 1.2737e-05, 3.0352e-04, 5.3811e-06, 2.8066e-06, 1.6021e-07,\n",
       "         1.0111e-05, 1.6589e-06, 2.0659e-06, 2.9200e-05, 1.2738e-04, 5.2634e-06,\n",
       "         2.7385e-08, 1.9561e-05, 1.8279e-08, 9.2990e-06, 1.1076e-06],\n",
       "        [2.0992e-04, 6.8257e-07, 1.2950e-05, 3.0685e-07, 1.9627e-07, 2.3457e-07,\n",
       "         3.8390e-06, 6.3515e-06, 1.9415e-05, 4.6832e-06, 3.4148e-09, 1.4882e-05,\n",
       "         2.7175e-07, 3.1340e-06, 2.2480e-06, 1.5891e-06, 7.6151e-06, 3.0911e-06,\n",
       "         5.2165e-07, 4.4287e-07, 3.4768e-06, 6.7344e-06, 5.4282e-06, 1.4331e-04,\n",
       "         2.1621e-07, 9.5918e-07, 1.0214e-07, 9.7699e-08, 1.3245e-06],\n",
       "        [4.5682e-06, 3.3590e-07, 1.5843e-04, 1.7928e-04, 1.1208e-07, 8.8080e-06,\n",
       "         1.0247e-05, 2.7954e-07, 2.7285e-06, 3.4113e-06, 2.0531e-06, 5.3859e-05,\n",
       "         3.5024e-05, 9.9957e-06, 2.4163e-07, 5.9765e-06, 1.0526e-06, 6.4620e-05,\n",
       "         2.3939e-08, 5.0615e-06, 1.3952e-04, 5.2282e-05, 8.2418e-07, 3.9734e-06,\n",
       "         1.2719e-06, 7.6979e-06, 6.9030e-07, 2.9316e-07, 5.4637e-06],\n",
       "        [6.1780e-08, 6.7911e-08, 1.2390e-06, 5.7116e-05, 2.0334e-06, 1.0153e-05,\n",
       "         2.5231e-06, 6.9672e-07, 5.1546e-06, 5.1297e-07, 1.4127e-04, 6.4066e-07,\n",
       "         1.5544e-04, 3.7416e-07, 9.3450e-09, 3.0385e-07, 8.5215e-08, 3.1655e-07,\n",
       "         1.2798e-08, 7.3027e-07, 6.8063e-06, 8.9812e-05, 1.1823e-07, 2.5259e-07,\n",
       "         3.3274e-07, 7.1020e-06, 8.4304e-07, 5.9940e-07, 1.8738e-05],\n",
       "        [7.5846e-08, 2.5191e-06, 3.4618e-06, 6.1742e-08, 3.0363e-07, 7.7527e-06,\n",
       "         2.5871e-07, 8.1696e-07, 5.3470e-06, 1.5712e-07, 1.1256e-06, 2.2299e-07,\n",
       "         6.3759e-09, 4.6673e-07, 6.0398e-09, 2.7504e-07, 2.5244e-09, 4.9188e-09,\n",
       "         1.2802e-06, 5.0538e-05, 3.5534e-06, 2.2287e-06, 1.7223e-09, 1.4306e-05,\n",
       "         6.8211e-05, 3.3634e-07, 3.5403e-07, 2.0042e-08, 7.1675e-07],\n",
       "        [4.6509e-05, 3.3989e-04, 2.9813e-08, 5.5488e-07, 9.2788e-07, 9.1523e-05,\n",
       "         3.8221e-05, 3.2209e-06, 7.9309e-06, 5.2608e-07, 1.5885e-06, 9.7267e-05,\n",
       "         1.0775e-06, 4.4973e-04, 1.1140e-03, 4.2160e-06, 5.0675e-08, 4.6160e-07,\n",
       "         3.7948e-04, 5.0215e-05, 5.2686e-08, 4.1040e-06, 8.6719e-08, 1.7593e-05,\n",
       "         9.2042e-06, 6.2483e-05, 2.9898e-05, 1.4150e-04, 1.0395e-06],\n",
       "        [6.7189e-07, 5.4233e-07, 3.0787e-04, 2.0714e-05, 1.3260e-06, 7.9999e-06,\n",
       "         1.2891e-06, 3.6829e-07, 2.6310e-06, 4.4515e-07, 4.1480e-05, 6.9277e-07,\n",
       "         1.7245e-07, 2.3201e-05, 9.2295e-08, 4.9436e-07, 5.7418e-07, 5.1266e-07,\n",
       "         1.7335e-07, 4.8727e-06, 1.2502e-05, 1.2919e-05, 7.0174e-08, 2.1683e-06,\n",
       "         1.7004e-06, 2.0651e-06, 2.2975e-07, 2.8664e-07, 1.4190e-06],\n",
       "        [4.6856e-05, 3.6483e-06, 2.2145e-08, 4.4686e-06, 6.0084e-08, 1.8141e-05,\n",
       "         9.9641e-06, 2.6165e-06, 2.8358e-06, 1.1768e-07, 8.1378e-07, 1.6793e-05,\n",
       "         2.4550e-06, 1.7396e-06, 9.2465e-07, 4.7680e-05, 1.9927e-08, 5.3479e-08,\n",
       "         3.7162e-08, 4.4958e-05, 2.6163e-07, 8.9283e-06, 1.1538e-06, 4.8616e-07,\n",
       "         9.6767e-08, 2.4196e-05, 7.0397e-07, 1.3664e-06, 2.4191e-06],\n",
       "        [2.3207e-06, 1.6682e-05, 1.4483e-07, 7.5331e-08, 1.4260e-04, 4.9802e-07,\n",
       "         1.3722e-04, 2.8200e-03, 2.3197e-05, 7.4167e-07, 7.8725e-06, 3.6783e-06,\n",
       "         2.2076e-06, 4.5337e-05, 6.2388e-04, 3.9571e-06, 1.4378e-06, 1.4637e-07,\n",
       "         3.2294e-04, 9.5533e-06, 1.2537e-08, 3.1927e-07, 3.2629e-07, 1.7963e-07,\n",
       "         4.5099e-08, 7.6699e-06, 3.6413e-07, 5.9583e-06, 1.1739e-07],\n",
       "        [6.9705e-06, 7.9949e-08, 3.6336e-06, 2.3753e-06, 1.8206e-07, 3.4269e-07,\n",
       "         3.8156e-06, 1.2568e-06, 5.6209e-06, 1.2636e-06, 5.3207e-06, 8.7852e-07,\n",
       "         2.0312e-07, 6.5738e-07, 3.5361e-07, 1.7169e-07, 9.5533e-07, 2.8310e-08,\n",
       "         3.0272e-07, 1.3633e-06, 6.8072e-06, 3.6247e-06, 7.2191e-07, 2.0708e-05,\n",
       "         1.5803e-09, 4.7780e-07, 3.5263e-09, 1.0820e-07, 1.9985e-06]],\n",
       "       grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5fdcb694-405d-4df5-8d4a-e82b6e95f3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_vgae_model_gradients(model, tensor):\n",
    "    # Create a random input adjacency matrix\n",
    "    adjref = tensor.adj[0]\n",
    "\n",
    "    # Create an instance of your VGAE model  # Replace with your actual model class\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Enable gradient computation for the input adjacency matrix\n",
    "    # tensor.adj.requires_grad = True\n",
    "    tensor.x[0].requires_grad = True\n",
    "    tensor.x[1].requires_grad = True\n",
    "    tensor.x[2].requires_grad = True\n",
    "    tensor.x[3].requires_grad = True\n",
    "\n",
    "    # Forward pass through the VGAE model\n",
    "    adj_reconstructed, mean, log_var = model(tensor)\n",
    "\n",
    "    # Compute the loss using your vgae_loss function\n",
    "    loss = vgae_loss(adj_reconstructed, adjref, mean, log_var)\n",
    "\n",
    "    # Perform gradient checking\n",
    "    test_passed = torch.autograd.gradcheck(lambda adj: vgae_loss(*model(adj)), (tensor,), eps=1e-6, atol=1e-4)\n",
    "\n",
    "    if test_passed:\n",
    "        print(\"Gradient check passed!\")\n",
    "    else:\n",
    "        print(\"Gradient check failed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fe6a5ade-62bc-4836-a93c-8dbca7a31233",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "gradcheck expects at least one input tensor to require gradient, but none of the them have requires_grad=True.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_vgae_model_gradients(encoder, tensor)\n",
      "Cell \u001b[0;32mIn[50], line 24\u001b[0m, in \u001b[0;36mtest_vgae_model_gradients\u001b[0;34m(model, tensor)\u001b[0m\n\u001b[1;32m     21\u001b[0m loss \u001b[38;5;241m=\u001b[39m vgae_loss(adj_reconstructed, adjref, mean, log_var)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Perform gradient checking\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m test_passed \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgradcheck(\u001b[38;5;28;01mlambda\u001b[39;00m adj: vgae_loss(\u001b[38;5;241m*\u001b[39mmodel(adj)), (tensor,), eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m test_passed:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGradient check passed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/autograd/gradcheck.py:2070\u001b[0m, in \u001b[0;36mgradcheck\u001b[0;34m(func, inputs, eps, atol, rtol, raise_exception, check_sparse_nnz, nondet_tol, check_undefined_grad, check_grad_dtypes, check_batched_grad, check_batched_forward_grad, check_forward_ad, check_backward_ad, fast_mode, masked)\u001b[0m\n\u001b[1;32m   2068\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   2069\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2070\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _gradcheck_helper(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/autograd/gradcheck.py:2090\u001b[0m, in \u001b[0;36m_gradcheck_helper\u001b[0;34m(func, inputs, eps, atol, rtol, nondet_tol, check_undefined_grad, check_grad_dtypes, check_batched_grad, check_batched_forward_grad, check_forward_ad, check_backward_ad, fast_mode, masked)\u001b[0m\n\u001b[1;32m   2073\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_gradcheck_helper\u001b[39m(\n\u001b[1;32m   2074\u001b[0m     func,\n\u001b[1;32m   2075\u001b[0m     inputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2087\u001b[0m     masked,\n\u001b[1;32m   2088\u001b[0m ):\n\u001b[1;32m   2089\u001b[0m     tupled_inputs \u001b[38;5;241m=\u001b[39m _as_tuple(inputs)\n\u001b[0;32m-> 2090\u001b[0m     _check_inputs(tupled_inputs)\n\u001b[1;32m   2092\u001b[0m     func_out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39mtupled_inputs)\n\u001b[1;32m   2093\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m _differentiable_outputs(func_out)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/autograd/gradcheck.py:943\u001b[0m, in \u001b[0;36m_check_inputs\u001b[0;34m(tupled_inputs)\u001b[0m\n\u001b[1;32m    940\u001b[0m         any_input_requiring_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m any_input_requiring_grad:\n\u001b[0;32m--> 943\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    944\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgradcheck expects at least one input tensor to require gradient, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    945\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut none of the them have requires_grad=True.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    946\u001b[0m     )\n\u001b[1;32m    947\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: gradcheck expects at least one input tensor to require gradient, but none of the them have requires_grad=True."
     ]
    }
   ],
   "source": [
    "test_vgae_model_gradients(encoder, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6ae0fdc0-619a-4314-9923-d4a465ec6524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [1., 0., 0.],\n",
       "         [1., 0., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [1., 0., 0.],\n",
       "         [1., 0., 0.],\n",
       "         [1., 0., 0.],\n",
       "         [1., 0., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [1., 0., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [1., 0., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [1., 0., 0.]]),\n",
       " tensor([[0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.],\n",
       "         [0., 0., 1.]]),\n",
       " tensor([[1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.]]),\n",
       " tensor([[1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.],\n",
       "         [0., 1.]]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
